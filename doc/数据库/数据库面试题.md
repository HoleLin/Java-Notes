### 数据库面试题

* **参考文献**
  * [分布式系统架构面试题汇总（万字总结）](https://zhuanlan.zhihu.com/p/267712773)

#### 主从复制

* 主从复制一般采用多主多从的方案

##### 多主条件下数据一致性问题

* **描述**

  > 也就是两台主数据库同时更新了数据，以谁的为主

* **解决方案**

  * **根据时间戳进行判断**
    * 最后写入的，也就是时间戳在后面的，覆盖时间戳在前面的。
  * **通过投票进行解决**。

##### **主节点挂掉了怎么办？**

* **解决方案**

  > 多主多从模式中，几台主服务器相互监督观察，只要对面的有更新自己也更新；

#### 分库分表

* **垂直分库分表**

  > 垂直分表意味着对这个表大部分增删改查的操作需要跨库，系统开销太大，一般不使用。垂直分库也会带来事务等问题，解决办法是Rpc

* **水平分库分表**

  * **根据数值范围**
    * 按照时间区间或ID区间来切分。例如：将userId为1~9999的记录分到第一个库，10000~20000的分到第二个库，以此类推。
    * **优点**:
      * 单表大小可控;
      * 天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移;
      * 使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。
    * **缺点**:
      * 热点数据可能较为集中，造成压力。
  * **根据数据取模**
    * 例如：将 Customer 表根据 no字段切分到4个库中，余数为0的放到第一个库，余数为1的放到第二个库，以此类推。
    * **优点**:
      * 数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈
    * **缺点**:
      * 扩容比较麻烦，新增加一个数据库时，需要重新hash

* **分库分表出现的问题**

  * **事务一致性问题(垂直分库问题)**
    * **解决分案**
      * **分布式事务**
        *  当更新内容同时分布在不同库中，垂直分库，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用"XA协议"和"两阶段提交"处理。
      * **最终一致性**
        * 只要在允许的时间段内达到最终一致性即可，可采用事务补偿的方式。也就是基于日志，进行同步；
    
  * **跨节点关联查询 join 问题（垂直分库问题）**
    * **解决方案**
      * **全局表**
        * 全局表，也可看做是"数据字典表"，就是系统中所有模块都可能依赖的一些表，为了避免跨库join查询，可以将这类表在每个数据库中都保存一份。这些数据通常很少会进行修改，所以也不担心一致性的问题。
      * **字段冗余**
        * 在系统层面，分两次查询，第一次查询的结果集中找出关联数据id，然后根据id发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装。
      * **ER分片**
        * 关系型数据库中，如果可以先确定表之间的关联关系，并将那些存在关联关系的表记录存放在同一个分片上
    
  * **跨节点分页、排序、函数问题（水平分库问题）**

    * **分页问题**

      > 需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。

    * **函数问题**

      > 在使用Max、Min、Sum、Count之类的函数进行计算的时候，也需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。

  * **分布式ID问题**

    * **描述**

      > 在分库分表的环境中，数据分布在不同的分片上，不能再借助数据库自增长特性直接生成，否则会造成不同分片上的数据表主键会重复。简单介绍下使用和了解过的几种 ID 生成算法。

    * **分布式ID定义**

      * 基本的要求包括：
        * 全局唯一，区别于单点系统的唯一，全局是要求分布式系统内唯一。
        * 有序性，通常都需要保证生成的 ID 是有序递增的。例如，在数据库存储等场景中，有序 ID 便于确定数据位置，往往更加高效。

    * **解决方案**

      * **Twitter 的 Snowflake（又名“雪花算法”）**

        > 这种方案把64-bit分别划分成多段，分开来标示机器、时间等
        >
        > snowflake-64-bit
        >
        > ​										41-bit时间戳	  								10bit-workerId   10bit-序列号	
        >
        > ​	|---------------------------------------------------------------------------|  |--------------|  |------------------|		
        >
        > **0** - 00000000 00000000 00000000 00000000 00000000 0 - 0000000 00 - 0000000 0000
        >
        > * 头部是 1 位的正负标识位。
        >
        > * 紧跟着的高位部分包含 41 位时间戳，通常使用 System.currentTimeMillis()。
        >
        > * 后面是 10 位的 WorkerID，标准定义是 5 位数据中心 + 5 位机器 ID，组成了机器编号，以区分不同的集群节点。
        >
        > * 最后的 12 位就是单位毫秒内可生成的序列号数目的理论极限。
        >
        > 这种分配方式可以保证在任何一个IDC的任何一台机器在任意毫秒内生成的ID都是不同的。根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。

        * Java实现

        ```java
        /**
         * From https://github.com/relops/snowflake
         * A snowflake is a source of k-ordered unique 64-bit integers.
         */
        public class Snowflake {
        
          public static final int NODE_SHIFT = 10;
          public static final int SEQ_SHIFT = 12;
        
          public static final short MAX_NODE = 1024;
          public static final short MAX_SEQUENCE = 4096;
        
          private short sequence;
          private long referenceTime;
        
          private int node;
        
          /**
           * A snowflake is designed to operate as a singleton instance within the context of a node.
           * If you deploy different nodes, supplying a unique node id will guarantee the uniqueness
           * of ids generated concurrently on different nodes.
           *
           * @param node This is an id you use to differentiate different nodes.
           */
          public Snowflake(int node) {
            if (node < 0 || node > MAX_NODE) {
              throw new IllegalArgumentException(String.format("node must be between %s and %s", 0, MAX_NODE));
            }
            this.node = node;
          }
        
          /**
           * Generates a k-ordered unique 64-bit integer. Subsequent invocations of this method will produce
           * increasing integer values.
           *
           * @return The next 64-bit integer.
           */
          public long next() {
        
            long currentTime = System.currentTimeMillis();
            long counter;
        
            synchronized(this) {
        
              if (currentTime < referenceTime) {
                throw new RuntimeException(String.format("Last referenceTime %s is after reference time %s", referenceTime, currentTime));
              } else if (currentTime > referenceTime) {
                this.sequence = 0;
              } else {
                if (this.sequence < Snowflake.MAX_SEQUENCE) {
                  this.sequence++;
                } else {
                  throw new RuntimeException("Sequence exhausted at " + this.sequence);
                }
              }
              counter = this.sequence;
              referenceTime = currentTime;
            }
        
            return currentTime << NODE_SHIFT << SEQ_SHIFT | node << SEQ_SHIFT | counter;
          }
        
        }
        ```

        * [百度](https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md)
        * 美团
          * [博客](https://tech.meituan.com/2017/04/21/mt-leaf.html)
          * [Github](https://github.com/Meituan-Dianping/Leaf)
        * 滴滴
          * [Github](https://github.com/didi/tinyid)

    * **利用Zookeeper生成唯一ID**

      > Zookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。

    * **Redis生成ID**

      > 这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现。

#### 为什么要使用索引?

* 通过创建唯一性索引,可以保证数据库表中每一行数据的唯一性;
* 可以大大加快数据的检索速度,这也是创建索引的最主要的原因;
* 帮助服务器避免排序和临时表;

* 将随机IO变成顺序IO;
* 可以加速表和表之间的连接,特别是在实现数据的参考完整性方面特别有意义;

#### InnoDB为什么要用自增id作为主键?

* 如果表使用自增主键,那么每次插入新的记录,记录就会顺序添加到当前索引节点的后续位置,当一页写满,就会自动开辟一个新的页.如果使用非自增主键,由于每次插入主键的值近似随机,因此每次新纪录都要被插到现有索引页得中间某个位置,频繁的移动,分页操作造成了大量碎片,得到了不够紧凑的索引结构,后续不得不通过OPTIMIZE TABLE(optimize table) 来重建表并优化填充页面.

#### MyISAM和InnoDB实现B树索引方式的区别是什么？

* MyISAM，B+Tree叶节点的data域存放的是数据记录的地址，在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的key存在，则取出其data域的值，然后以data域的值为地址读取相应的数据记录，这被称为“非聚簇索引”;
* InnoDB，其数据文件本身就是索引文件，相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的节点data域保存了完整的数据记录，这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引，这被称为“聚簇索引”或者聚集索引，而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。
* 在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议使用过长的字段为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。

#### 数据库引擎InnoDB与MyISAM的区别

* **MyISAM**
  * 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。
  * 提供了大量的特性，包括压缩表、空间数据索引等。
  * 不支持事务。
  * 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入(CONCURRENT INSERT)。
* **InnoDB**
  * 是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。
  * 实现了四个标准的隔离级别，默认级别是可重复读(REPEATABLE READ)。在可重复读隔离级别下，通过多版本并发控制(MVCC)+ 间隙锁(Next-Key Locking)防止幻影读。
  * 主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。
  * 内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。
  * 支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。
* **总结**
  * 事务: InnoDB 是事务型的，可以使用 `Commit` 和 `Rollback` 语句。
  * 并发: MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
  * 外键: InnoDB 支持外键。
  * 备份: InnoDB 支持在线热备份。
  * 崩溃恢复: MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
  * 其它特性: MyISAM 支持压缩表和空间数据索引。

#### MySQL索引主要使用的两种数据结构是什么？

* **哈希索引**，对于哈希索引来说，底层的数据结构肯定是哈希表，因此**在绝大多数需求为单条记录查询**的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引

* **BTree索引**，Mysql的BTree索引使用的是B树中的B+Tree，BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。

  但对于主要的两种存储引擎（MyISAM和InnoDB）的实现方式是不同的。

#### 说一下MySQL是如何执行一条SQL的？具体步骤有哪些？

* Server层按顺序执行sql的步骤为：

  > 1. 客户端请求->
  > 2. 连接器（验证用户身份，给予权限） ->
  > 3. 查询缓存（存在缓存则直接返回，不存在则执行后续操作）->
  > 4. 分析器（对SQL进行词法分析和语法分析操作） ->
  > 5. 优化器（主要对执行的SQL优化选择最优的执行方案方法） ->
  > 6. 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）->
  > 7. 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）

#### 你了解MySQL的内部构造吗？一般可以分为哪两个部分？

* 可以分为服务层和存储引擎层两部分，其中：

  **服务层包括连接器、查询缓存、分析器、优化器、执行器等**，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

  **存储引擎层负责数据的存储和提取**。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认的存储引擎。

#### 说一说Drop、Delete与Truncate的共同点和区别

* **Drop、Delete、Truncate都表示删除，但是三者有一些差别：**
  
  * **Delete**用来删除表的全部或者一部分数据行，执行Delete之后，用户需要提交(commmit)或者回滚(rollback)来执行删除或者撤销删除，会触发这个表上所有的delete触发器。
  * **Truncate**删除表中的所有数据，这个操作不能回滚，也不会触发这个表上的触发器，TRUNCATE比Delete更快，占用的空间更小。
  * **Drop**命令从数据库中删除表，所有的数据行，索引和权限也会被删除，所有的DML触发器也不会被触发，这个命令也不能回滚。
* 因此，**在不再需要一张表的时候，用Drop；在想删除部分数据行时候，用Delete；在保留表而删除所有数据的时候用Truncate。**
  
  > 1. DELETE语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。TRUNCATE TABLE 则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。
  > 2. 表和索引所占空间。当表被TRUNCATE 后，这个表和索引所占用的空间会恢复到初始大小，而DELETE操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。
  > 3. 一般而言，drop > truncate > delete
  > 4. 应用范围。TRUNCATE 只能对TABLE；DELETE可以是table和view
  > 5. TRUNCATE 和DELETE只删除数据，而DROP则删除整个表（结构和数据）。
  > 6. truncate与不带where的delete ：只删除数据，而不删除表的结构（定义）drop语句将删除表的结构被依赖的约束（constrain),触发器（trigger)索引（index);依赖于该表的存储过程/函数将被保留，但其状态会变为：invalid。
  > 7. delete语句为DML（Data Manipulation Language),这个操作会被放到 rollback segment中,事务提交后才生效。如果有相应的 tigger,执行的时候将被触发。
  > 8. truncate、drop是DDL（Data Define Language),操作立即生效，原数据不放到 rollback segment中，不能回滚
  > 9. 在没有备份情况下，谨慎使用 drop 与 truncate。要删除部分数据行采用delete且注意结合where来约束影响范围。回滚段要足够大。要删除表用drop;若想保留表而将表中数据删除，如果与事务无关，用truncate即可实现。如果和事务有关，或老是想触发trigger,还是用delete。
  > 10. Truncate table 表名 速度快,而且效率高,因为: truncate table 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少。DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。
  > 11. TRUNCATE TABLE 删除表中的所有行，但表结构及其列、约束、索引等保持不变。新行标识所用的计数值重置为该列的种子。如果想保留标识计数值，请改用 DELETE。如果要删除表定义及其数据，请使用 DROP TABLE 语句。
  > 12. 对于由 FOREIGN KEY 约束引用的表，不能使用 TRUNCATE TABLE，而应使用不带 WHERE 子句的 DELETE 语句。由于 TRUNCATE TABLE 不记录在日志中，所以它不能激活触发器。

#### MySQL优化了解吗？说一下从哪些方面可以做到性能优化？

* 为搜索字段创建索引
* 避免使用 Select *，列出需要查询的字段
* 垂直分割分表
* 选择正确的存储引擎

#### 数据库隔离级别

* **未提交读**，事务中发生了修改，即使没有提交，其他事务也是可见的，比如对于一个数A原来50修改为100，但是我还没有提交修改，另一个事务看到这个修改，而这个时候原事务发生了回滚，这时候A还是50，但是另一个事务看到的A是100.**可能会导致脏读、幻读或不可重复读**

* **提交读**，对于一个事务从开始直到提交之前，所做的任何修改是其他事务不可见的，举例就是对于一个数A原来是50，然后提交修改成100，这个时候另一个事务在A提交修改之前，读取的A是50，刚读取完，A就被修改成100，这个时候另一个事务再进行读取发现A就突然变成100了；**可以阻止脏读，但是幻读或不可重复读仍有可能发生**

* **重复读**，就是对一个记录读取多次的记录是相同的，比如对于一个数A读取的话一直是A，前后两次读取的A是一致的；**可以阻止脏读和不可重复读，但幻读仍有可能发生**

* **可串行化读**，在并发情况下，和串行化的读取的结果是一致的，没有什么不同，比如不会发生脏读和幻读；**该级别可以防止脏读、不可重复读以及幻读**

    | 隔离级别                  | 脏读 | 不可重复读 | 幻影读 |
    | :------------------------ | :--- | :--------- | :----- |
    | READ-UNCOMMITTED 未提交读 | √    | √          | √      |
    | READ-COMMITTED 提交读     | ×    | √          | √      |
    | REPEATABLE-READ 重复读    | ×    | ×          | √      |
    | SERIALIZABLE 可串行化读   | ×    | ×          | ×      |

* MySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ**（可重读）

* **这里需要注意的是**：与 SQL 标准不同的地方在于InnoDB 存储引擎在 REPEATABLE-READ（可重读）事务隔离级别 下使用的是**Next-Key Lock 锁**算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的。所以 说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 已经可以完全保证事务的隔离性要 求，即达到了 SQL标准的SERIALIZABLE(可串行化)隔离级别。

  因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内 容):，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）并不会有任何性能损失**。

  InnoDB 存储引擎在分布式事务 的情况下一般会用到SERIALIZABLE(可串行化)隔离级别。

#### 数据库并发事务会带来哪些问题？

* 数据库并发会带来脏读、幻读、丢弃更改、不可重复读这四个常见问题，其中：

  * **脏读**：第一个事务首先读取var变量为50，接着准备更新为100的时，并未提交，第二个事务已经读取var为100，此时第一个事务做了回滚。最终第二个事务读取的var和数据库的var不一样。

  * **幻读**：T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。

  * **丢弃修改**：两个写事务T1 T2同时对A=0进行递增操作，结果T2覆盖T1，导致最终结果是1 而不是2，事务被覆盖。

  * **不可重复读**：T2 读取一个数据，然后T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。

* **不可重复读的重点是修改，幻读的重点在于新增或者删除。**

#### 都知道数据库索引采用B+树而不是B树，原因也有很多，主要原因是什么？

* 主要原因：B+树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中基于范围的查询是非常频繁的，而B树只能中序遍历所有节点，效率太低。

#### 文件索引和数据库索引为什么使用B+树?

> 文件与数据库都是需要较大的存储，也就是说，它们都不可能全部存储在内存中，故需要存储到磁盘上。而所谓索引，则为了数据的快速定位与查找，那么索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数，因此B+树相比B树更为合适。数据库系统巧妙利用了局部性原理与磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入，而红黑树这种结构，高度明显要深的多，并且由于逻辑上很近的节点(父子)物理上可能很远，无法利用局部性。
>
> 最重要的是，B+树还有一个最大的好处：方便扫库。
>
> B树必须用中序遍历的方法按序扫库，而B+树直接从叶子结点挨个扫一遍就完了，B+树支持range-query非常方便，而B树不支持，这是数据库选用B+树的最主要原因。
>
> B+树查找效率更加稳定，B树有可能在中间节点找到数据，稳定性不够。
>
> B+tree的磁盘读写代价更低：B+tree的内部结点并没有指向关键字具体信息的指针(红色部分)，因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一块盘中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多，相对来说IO读写次数也就降低了；
>
> B+tree的查询效率更加稳定：由于内部结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引，所以，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；

#### MySQL中为什么要有事务回滚机制？

> 而在 MySQL 中，恢复机制是通过回滚日志（undo log）实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后在对数据库中的对应行进行写入。当事务已经被提交之后，就无法再次回滚了。
>
> 回滚日志作用：
>
> 1) 能够在发生错误或者用户执行 ROLLBACK 时提供回滚相关的信息
>
> 2) 在整个系统发生崩溃、数据库进程直接被杀死后，当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚，这也就需要回滚日志必须先于数据持久化到磁盘上，是我们需要先写日志后写数据库的主要原因。

#### 数据库悲观锁和乐观锁的原理和应用场景分别有什么？

* 悲观锁，先获取锁，再进行业务操作，一般就是利用类似 SELECT … FOR UPDATE 这样的语句，对数据加锁，避免其他事务意外修改数据。当数据库执行SELECT … FOR UPDATE时会获取被select中的数据行的行锁，select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。
* 乐观锁，先进行业务操作，只在最后实际更新数据时进行检查数据是否被更新过。Java 并发包中的 AtomicFieldUpdater 类似，也是利用 CAS 机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。

#### 数据库为什么要进行分库和分表呢？都放在一个库或者一张表中不可以吗？

* 分库与分表的目的在于，减小数据库的单库单表负担，提高查询性能，缩短查询时间。

  **通过分表**，可以减少数据库的单表负担，将压力分散到不同的表上，同时因为不同的表上的数据量少了，起到提高查询性能，缩短查询时间的作用，此外，可以很大的缓解表锁的问题。分表策略可以归纳为垂直拆分和水平拆分:

  **水平分表**：取模分表就属于随机分表，而时间维度分表则属于连续分表。如何设计好垂直拆分，我的建议：将不常用的字段单独拆分到另外一张扩展表. 将大文本的字段单独拆分到另外一张扩展表, 将不经常修改的字段放在同一张表中，将经常改变的字段放在另一张表中。对于海量用户场景，可以考虑取模分表，数据相对比较均匀，不容易出现热点和并发访问的瓶颈。

  **库内分表**，仅仅是解决了单表数据过大的问题，但并没有把单表的数据分散到不同的物理机上，因此并不能减轻 MySQL 服务器的压力，仍然存在同一个物理机上的资源竞争和瓶颈，包括 CPU、内存、磁盘 IO、网络带宽等。

  **分库与分表带来的分布式困境与应对之策**数据迁移与扩容问题----一般做法是通过程序先读出数据，然后按照指定的分表策略再将数据写入到各个分表中。分页与排序问题----需要在不同的分表中将数据进行排序并返回，并将不同分表返回的结果集进行汇总和再次排序，最后再返回给用户。

#### MySQL中有四种索引类型，可以简单说说吗？

* **FULLTEXT** ：即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。
* **HASH** ：由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。
* **BTREE** ：BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。
* **RTREE** ：RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。相对于BTREE，RTREE的优势在于范围查找

